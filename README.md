# Enhanced Landslide Detection Using Spatial-Channel Attention with ResNet50

## ğŸ“‹ Project Overview

This project implements an advanced **semantic segmentation model** for detecting landslides in satellite imagery combined with Digital Elevation Model (DEM) data. The model leverages a custom **ResNet50 architecture** enhanced with **Efficient Channel Attention (ECA)** mechanisms to achieve high accuracy in landslide identification across complex topography, particularly in northern Pakistan.

## ğŸ¯ Key Features

- **Multimodal Data Fusion**: Combines RGB satellite imagery with DEM data for richer feature representation
- **ECA Attention Mechanism**: Efficient channel attention with minimal computational overhead (4 parameters, 45.31K FLOPs)
- **Custom ResNet50**: Modified ResNet50 with integrated ECA attention in bottleneck blocks
- **High Accuracy**: Achieves 91%+ accuracy on validation data
- **Interactive Web Interface**: Gradio-based UI for real-time predictions and visualizations
- **GPU Acceleration**: Multi-GPU support via `nn.DataParallel`

---

## ğŸ“Š Dataset

### Bijie Landslide Dataset
- **Source**: Kaggle (hanstankman/bijie-landslidedataset)
- **Size**: ~502 MB
- **Structure**:
  ```
  Bijie-landslide-dataset/
  â”œâ”€â”€ landslide/
  â”‚   â”œâ”€â”€ image/          (RGB satellite images)
  â”‚   â”œâ”€â”€ dem/            (Digital Elevation Models)
  â”‚   â”œâ”€â”€ mask/           (Ground truth segmentation masks)
  â”‚   â””â”€â”€ polygon_coordinate/  (Coordinate files)
  â””â”€â”€ non-landslide/
      â”œâ”€â”€ image/
      â””â”€â”€ dem/
  ```
- **Data Split**: 67% training / 33% validation
- **Image Size**: Resized to 224Ã—224 pixels
- **Channels**: 4 (RGB + DEM)

---

## ğŸ—ï¸ Architecture

### Model Components

#### 1. **ECA Attention Module** (`ECAAttention`)
```
Input â†’ GlobalAvgPool â†’ Conv1D â†’ Sigmoid â†’ Channel Weighting â†’ Output
```
- **Purpose**: Adaptively weights feature channels
- **Parameters**: 4
- **FLOPs**: 45.31K (per 512Ã—7Ã—7 feature map)
- **Initialization**: He initialization for stability

#### 2. **Bottleneck Block with ECA**
```
Input â†’ [1Ã—1 Conv] â†’ [3Ã—3 Conv] â†’ [1Ã—1 Conv] 
         â†“ (Skip connection)
         â†’ [ECA Attention] â†’ ReLU â†’ Output
```
- Features: Batch normalization, ReLU activation, shortcut connections

#### 3. **ResNet50 Backbone**
| Layer | Blocks | Output Channels | Stride |
|-------|--------|-----------------|--------|
| Conv1 | 1      | 64              | 2      |
| Conv2 | 3      | 64â†’256          | 1      |
| Conv3 | 4      | 128â†’512         | 2      |
| Conv4 | 6      | 256â†’1024        | 2      |
| Conv5 | 3      | 512â†’2048        | 2      |

#### 4. **Custom Output Module** (`CustomModel`)
- **UpsampleAndReduceChannels**: 
  - Bilinear upsampling: 7Ã—7 â†’ 224Ã—224
  - Channel reduction: 2048 â†’ 2 channels
- **Output**: 2-channel segmentation map (landslide vs. non-landslide)

### Input Processing
- **Image**: RGB (3 channels) â†’ Normalize with ImageNet statistics
- **DEM**: Grayscale (1 channel) â†’ Normalize to [-1, 1]
- **Concatenation**: 3 + 1 = **4-channel input**
- **Data Augmentation**: Random horizontal flips (50% probability)

---

## ğŸ”§ Technical Stack

| Component | Version/Library |
|-----------|-----------------|
| Deep Learning | PyTorch |
| Computer Vision | torchvision, OpenCV, PIL |
| Data Processing | NumPy, Pandas |
| Visualization | Matplotlib, Gradio |
| ML Utilities | scikit-learn (train_test_split) |
| Model Analysis | torchsummary, thop |
| Environment | Google Colab (TPU/GPU) |

---

## ğŸ“ˆ Training Configuration

```python
# Loss Function
criterion = torch.nn.CrossEntropyLoss()

# Optimizer
optimizer = Adam(lr=0.0001)

# Training Parameters
â”œâ”€â”€ Batch Size: 8
â”œâ”€â”€ Epochs: 20
â”œâ”€â”€ Learning Rate: 1e-4
â”œâ”€â”€ Validation Split: 33%
â”œâ”€â”€ Device: GPU (CUDA) if available
â””â”€â”€ Data Workers: 4 (parallel loading)
```

### Training Metrics
| Metric | Training | Validation |
|--------|----------|-----------|
| Initial Loss | 0.1665 | 0.1891 |
| Initial Accuracy | 91.80% | 91.02% |
| Epoch 2 Loss | 0.1783 | 0.1985 |
| Epoch 2 Accuracy | 92.16% | 91.82% |

---

## ğŸ“¦ Installation & Setup

### Prerequisites
```bash
python >= 3.8
CUDA >= 11.0 (for GPU support)
```

### Install Dependencies
```bash
pip install torch torchvision
pip install kaggle kagglehub
pip install numpy opencv-python pillow
pip install matplotlib scikit-learn tqdm
pip install torchsummary thop
pip install gradio
```

### Setup Kaggle API (for dataset download)
```bash
# Download kaggle.json from https://www.kaggle.com/settings/account
mkdir -p ~/.kaggle
cp kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json
```

---

## ğŸš€ Usage

### 1. Data Preparation
```python
import kagglehub

# Download dataset
path = kagglehub.dataset_download("hanstankman/bijie-landslidedataset")
print("Path to dataset files:", path)
```

### 2. Dataset Loading
```python
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split

# Split data
train_indices, val_indices = train_test_split(
    range(len(dataset)), 
    test_size=0.33, 
    random_state=42
)

# Create loaders
train_loader = DataLoader(train_subset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_subset, batch_size=8, shuffle=False)
```

### 3. Model Training
```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

num_epochs = 20
for epoch in range(1, num_epochs + 1):
    train_loss, train_acc = train_one_epoch(epoch, model, train_loader, device)
    val_loss, val_acc = validate(epoch, model, val_loader, device)
    print(f"Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}")
```

### 4. Model Inference
```python
model.eval()
with torch.no_grad():
    outputs = model(input_tensor)
    predictions = torch.argmax(outputs, dim=1)
```

### 5. Launch Web Interface
```python
import gradio as gr

iface = gr.Interface(
    fn=visualize_segmentation,
    inputs=gr.Image(type="pil"),
    outputs="image",
    live=True
)
iface.launch()
```

---

## ğŸ“Š Results & Performance

### Model Metrics
- **Training Accuracy**: ~92%+
- **Validation Accuracy**: ~91%+
- **Model Parameters**: ~23.5M (ResNet50 + ECA)
- **Inference Time**: ~0.2s per image (GPU)

### Visualizations
The model generates 3-subplot comparisons:
1. **Input Image**: RGB satellite image with DEM overlay
2. **Ground Truth Mask**: Actual landslide regions
3. **Predicted Mask**: Model predictions

---

## ğŸ”„ Data Enhancement Functions

### Image Preprocessing
```python
def resize_and_normalize(image, target_size=(224, 224)):
    """Resize and normalize image to [0, 255]"""
    image = cv2.resize(image, target_size, interpolation=cv2.INTER_CUBIC)
    return (image - image.min()) / (image.max() - image.min()) * 255

def histogram_equalization(image):
    """Enhance contrast using YUV color space"""
    img_yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)
    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])
    return cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)

def add_noise(image, variance=0.1):
    """Add Gaussian noise for robustness"""
    gauss = np.random.normal(0, variance**0.5, image.shape)
    noisy = image + gauss * 255
    return np.clip(noisy, 0, 255).astype(np.uint8)
```

---

## ğŸ“ Project Structure

```
Enhanced_Landslide_Detection/
â”œâ”€â”€ Enhanced_Landslide Detection.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ outputs/
    â”œâ”€â”€ trained_model.pth
    â”œâ”€â”€ loss_curves.png
    â””â”€â”€ prediction_samples/
```

---

## ğŸ“ Key Concepts

### Semantic Segmentation
- **Task**: Pixel-level classification (landslide vs. non-landslide)
- **Output**: 2-channel probability map
- **Loss Function**: Cross-Entropy Loss for multi-class classification

### Efficient Channel Attention (ECA)
- **Advantage**: Captures channel interdependencies with minimal overhead
- **Mechanism**: 1D convolution on channel statistics
- **Application**: Applied in every bottleneck block

### Multimodal Fusion
- **RGB Data**: Spectral information from satellite imagery
- **DEM Data**: Topographic/elevation information
- **Fusion Strategy**: Channel concatenation (early fusion)

---

## ğŸ” Troubleshooting

| Issue | Solution |
|-------|----------|
| CUDA Out of Memory | Reduce batch size from 8 to 4 or 2 |
| Dataset not found | Verify Kaggle API credentials in `~/.kaggle/kaggle.json` |
| Gradio connection error | Add `share=True` in `iface.launch(share=True)` |
| Slow data loading | Reduce `num_workers` or increase to 8 |
| Low accuracy | Increase epochs, use learning rate scheduler |

---

## ğŸ“š References

- **ResNet**: He et al., "Deep Residual Learning for Image Recognition" (2015)
- **ECA-Net**: Wang et al., "ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks" (2020)
- **Segmentation**: Long et al., "Fully Convolutional Networks for Semantic Segmentation" (2015)
- **Dataset**: [Bijie Landslide Dataset on Kaggle](https://www.kaggle.com/datasets/hanstankman/bijie-landslidedataset)

---

## ğŸ“ Citation

If you use this project, please cite:
```bibtex
@project{landslide_detection_2024,
  title={Enhanced Landslide Detection Using Spatial-Channel Attention with ResNet50},
  author={Maqsood},
  year={2024},
  note={Kaggle Dataset: hanstankman/bijie-landslidedataset}
}
```

---

## ğŸ“„ License

This project is provided as-is for educational and research purposes.

---

## ğŸ‘¤ Author

**Maqsood**  
Specialization: Deep Learning, Computer Vision, Geospatial Analysis

---

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request with detailed description

---

## ğŸ“ Support

For issues, questions, or suggestions:
- Create an issue on GitHub
- Check existing documentation
- Refer to Kaggle dataset discussions

---

**Last Updated**: February 2, 2026  
**Status**: Active Development
